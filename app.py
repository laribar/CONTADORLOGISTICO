import av
import cv2
import numpy as np
import streamlit as st
import os
from collections import Counter
from ultralytics import YOLO
from streamlit_webrtc import webrtc_streamer, VideoTransformerBase, WebRtcMode, RTCConfiguration
import tempfile

# Configura√ß√£o do Streamlit
st.set_page_config(page_title="Contador de Objetos", layout="wide")
st.title("üì∑ Contador de Objetos ‚Äî Streamlit com YOLOv8")

# --- Verifica√ß√£o e Carregamento de Modelos ---
MODEL_DIR = "models"
yolo_model = None

st.sidebar.header("Configura√ß√µes")
mode = st.sidebar.selectbox("Modo de contagem", ["YOLO (Deep Learning)", "Cl√°ssico (Hough - c√≠rculos)"])

# ---------- Par√¢metros comuns ----------
draw_boxes = st.sidebar.checkbox("Desenhar anota√ß√µes", True)
show_fps = st.sidebar.checkbox("Mostrar FPS", True)

# === Sele√ß√£o da Fonte de M√≠dia e Upload de Arquivos ===
source_option = st.sidebar.selectbox(
    "Escolher Fonte de M√≠dia",
    ["Webcam (Live Stream)", "Carregar Imagem da Galeria", "Carregar V√≠deo Local"]
)

uploaded_file = None
if source_option == "Carregar Imagem da Galeria":
    uploaded_file = st.sidebar.file_uploader("Carregue um arquivo de imagem (PNG, JPG)", type=["png", "jpg", "jpeg"])
elif source_option == "Carregar V√≠deo Local":
    uploaded_file = st.sidebar.file_uploader("Carregue um arquivo de v√≠deo (MP4, AVI, MOV)", type=["mp4", "avi", "mov"])


# ---------- L√≥gica YOLO (Deep Learning) ----------
if mode.startswith("YOLO"):
    try:
        if not os.path.exists(MODEL_DIR):
            st.error(f"‚ùå Erro: Pasta '{MODEL_DIR}' n√£o encontrada. Crie-a e adicione seus modelos .pt.")
            st.stop()

        model_files = [f for f in os.listdir(MODEL_DIR) if f.endswith('.pt')]

        if not model_files:
            st.error(f"‚ùå Erro: Nenhum arquivo .pt encontrado em '{MODEL_DIR}'.")
            st.stop()

        selected_model_file = st.sidebar.selectbox("Escolher Modelo YOLO", model_files)
        model_path = os.path.join(MODEL_DIR, selected_model_file)

        conf_thres = st.sidebar.slider("Confian√ßa m√≠nima", 0.1, 0.9, 0.4, 0.05)
        iou_thres = st.sidebar.slider("IoU NMS", 0.1, 0.9, 0.5, 0.05)
        max_det = st.sidebar.slider("M√°ximo de detec√ß√µes", 50, 1000, 300, 10)

        @st.cache_resource(show_spinner="Carregando Modelo YOLO...")
        def load_model(path):
            return YOLO(path)

        yolo_model = load_model(model_path)
        st.sidebar.success(f"Modelo {selected_model_file} carregado com sucesso!")

    except Exception as e:
        st.error(f"‚ùå Erro ao carregar o modelo: {e}")
        st.stop()

# ---------- L√≥gica Hough (Cl√°ssico) ----------
else:
    dp = st.sidebar.slider("dp (resolu√ß√£o)", 0.8, 3.0, 1.2, 0.1)
    minDist = st.sidebar.slider("minDist entre centros", 5, 200, 28, 1)
    canny = st.sidebar.slider("Canny (param1)", 50, 300, 120, 1)
    acc_thr = st.sidebar.slider("Acumulador (param2)", 10, 200, 35, 1)
    minR = st.sidebar.slider("Raio m√≠nimo", 0, 200, 12, 1)
    maxR = st.sidebar.slider("Raio m√°ximo", 0, 400, 60, 1)

# ---------- Configura√ß√£o WebRTC Simplificada ----------
rtc_config = RTCConfiguration({
    "iceServers": [{"urls": ["stun:stun.l.google.com:19302"]}]
})


# =========================================================================
# === CLASSE TRANSFORMER CORRIGIDA ===
# =========================================================================
class ObjectCounterTransformer(VideoTransformerBase):
    def __init__(self, yolo_model=None):
        self.yolo_model = yolo_model
        self.counter = Counter()
        self.fps_hist = []
        self.prev_time = cv2.getTickCount() / cv2.getTickFrequency()

    def _update_fps(self):
        current_time = cv2.getTickCount() / cv2.getTickFrequency()
        fps = 1.0 / (current_time - self.prev_time + 1e-6)
        self.prev_time = current_time
        self.fps_hist.append(fps)
        if len(self.fps_hist) > 30:
            self.fps_hist.pop(0)
        return np.mean(self.fps_hist)
    
    def process_frame(self, img: np.ndarray) -> np.ndarray:
        if img is None or img.size == 0:
            return np.zeros((480, 640, 3), dtype=np.uint8)

        height, width = img.shape[:2]
        self.counter = Counter()

        try:
            if mode.startswith("YOLO") and self.yolo_model is not None:
                # Processamento YOLO
                results = self.yolo_model.predict(
                    source=img,
                    conf=conf_thres,
                    iou=iou_thres,
                    verbose=False,
                    max_det=max_det
                )
                
                detections = results[0]
                
                if detections.boxes is not None and len(detections.boxes) > 0:
                    boxes = detections.boxes.xyxy.cpu().numpy().astype(int)
                    classes = detections.boxes.cls.cpu().numpy().astype(int)
                    class_names = detections.names
                    
                    for (x1, y1, x2, y2), class_id in zip(boxes, classes):
                        class_name = class_names.get(class_id, str(class_id))
                        self.counter[class_name] += 1
                        
                        if draw_boxes:
                            cv2.rectangle(img, (x1, y1), (x2, y2), (0, 255, 0), 2)
                            cv2.putText(img, class_name, (x1, max(10, y1-6)), 
                                      cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 0), 2)
            
            else:
                # Processamento Hough Circles
                gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
                gray = cv2.medianBlur(gray, 9)
                
                circles = cv2.HoughCircles(
                    gray, cv2.HOUGH_GRADIENT, 
                    dp=dp, minDist=minDist,
                    param1=canny, param2=acc_thr,
                    minRadius=minR, maxRadius=maxR
                )
                
                if circles is not None:
                    circles = np.uint16(np.around(circles[0, :]))
                    self.counter["circulos"] = len(circles)
                    
                    if draw_boxes:
                        for (x, y, r) in circles:
                            cv2.circle(img, (x, y), r, (0, 255, 0), 2)
                            cv2.circle(img, (x, y), 2, (0, 0, 255), 3)

            # Exibir contadores na imagem
            y_offset = 30
            for obj_type, count in sorted(self.counter.items()):
                text = f"{obj_type}: {count}"
                
                # üö® CORRE√á√ÉO DE EXIBI√á√ÉO: Usamos cor e espessura robustas
                cv2.putText(img, text, (10, y_offset), 
                        cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 0, 255), 2) # Cor VERMELHA (BGR)
                y_offset += 30

        except Exception as e:
            error_text = f"Erro: {str(e)}"
            cv2.putText(img, error_text, (10, 30), 
                      cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 0, 255), 2)

        return img
    
    def transform(self, frame: av.VideoFrame) -> np.ndarray:
        try:
            if frame is None:
                return np.zeros((480, 640, 3), dtype=np.uint8)
            
            img = frame.to_ndarray(format="bgr24")
            processed_img = self.process_frame(img)
            
            if show_fps:
                fps = self._update_fps()
                cv2.putText(processed_img, f"FPS: {fps:.1f}", 
                          (img.shape[1] - 120, 30), 
                          cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 0), 2)
            
            return processed_img
            
        except Exception as e:
            error_img = np.zeros((480, 640, 3), dtype=np.uint8)
            cv2.putText(error_img, f"Erro: {str(e)}", (10, 30), 
                      cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 0, 255), 2)
            return error_img


# =========================================================================
# === L√ìGICA PRINCIPAL DE EXIBI√á√ÉO ===
# =========================================================================

if source_option == "Webcam (Live Stream)":
    st.info("üî¥ **Webcam ao Vivo** - Clique em 'START' para iniciar a c√¢mera")
    
    webrtc_ctx = webrtc_streamer(
        key="object-counter",
        mode=WebRtcMode.SENDRECV,
        rtc_configuration=rtc_config,
        
        # üö® ALTERA√á√ÉO CHAVE AQUI: Restri√ß√µes de M√≠dia
        media_stream_constraints={
            "video": {
                # Tenta for√ßar a resolu√ß√£o padr√£o (bom equil√≠brio)
                "width": {"ideal": 1280},
                "height": {"ideal": 720},
                # Tenta for√ßar 30 FPS.
                "frameRate": {"ideal": 60} 
            }, 
            "audio": False
        },
        
        video_processor_factory=lambda: ObjectCounterTransformer(yolo_model=yolo_model),
        async_processing=True,
    )
    
    if webrtc_ctx.state.playing:
        st.success("‚úÖ C√¢mera ativa - Detec√ß√£o em andamento")
    else:
        st.warning("‚è∏Ô∏è Clique em START para iniciar a c√¢mera")

elif uploaded_file is not None:
    if source_option == "Carregar Imagem da Galeria":
        try:
            file_bytes = np.asarray(bytearray(uploaded_file.read()), dtype=np.uint8)
            img = cv2.imdecode(file_bytes, cv2.IMREAD_COLOR)
            
            if img is not None:
                transformer = ObjectCounterTransformer(yolo_model=yolo_model)
                processed_img = transformer.process_frame(img)
                
                st.image(processed_img, channels="BGR", 
                        caption="üîç Resultado da Detec√ß√£o", 
                        use_column_width=True)
                
                if transformer.counter:
                    count_text = " | ".join([f"**{k}**: {v}" for k, v in transformer.counter.items()])
                    st.success(f"üìä **Contagem Total:** {count_text}")
                else:
                    st.warning("‚ö†Ô∏è Nenhum objeto detectado")
            else:
                st.error("‚ùå Erro: N√£o foi poss√≠vel carregar a imagem")
                
        except Exception as e:
            st.error(f"‚ùå Erro ao processar imagem: {str(e)}")

    elif source_option == "Carregar V√≠deo Local":
        try:
            tfile = tempfile.NamedTemporaryFile(delete=False, suffix='.mp4')
            tfile.write(uploaded_file.read())
            tfile.flush()
            
            cap = cv2.VideoCapture(tfile.name)
            transformer = ObjectCounterTransformer(yolo_model=yolo_model)
            
            stframe = st.empty()
            stop_processing = st.button("‚èπÔ∏è Parar Processamento")
            
            if cap.isOpened():
                st.info("üé• Processando v√≠deo...")
                
                while cap.isOpened() and not stop_processing:
                    ret, frame = cap.read()
                    if not ret:
                        break
                    
                    processed_frame = transformer.process_frame(frame)
                    stframe.image(processed_frame, channels="BGR", 
                                use_column_width=True)
                    
                    # Atualizar contagem
                    if transformer.counter:
                        count_text = " | ".join([f"**{k}**: {v}" for k, v in transformer.counter.items()])
                        st.info(f"üìä **Contagem Atual:** {count_text}")
                
                cap.release()
                
                if not stop_processing:
                    st.success("‚úÖ Processamento do v√≠deo conclu√≠do!")
                    final_count = " | ".join([f"**{k}**: {v}" for k, v in transformer.counter.items()])
                    st.info(f"üìã **Contagem Final:** {final_count}")
                else:
                    st.warning("‚èπÔ∏è Processamento interrompido pelo usu√°rio")
                    
            else:
                st.error("‚ùå Erro: N√£o foi poss√≠vel abrir o v√≠deo")
                
        except Exception as e:
            st.error(f"‚ùå Erro no processamento do v√≠deo: {str(e)}")
        finally:
            if 'tfile' in locals():
                os.unlink(tfile.name)

else:
    if source_option != "Webcam (Live Stream)":
        st.info("üìÅ Por favor, carregue um arquivo na barra lateral para iniciar o processamento.")


# =========================================================================
# === INSTRU√á√ïES DE USO ===
# =========================================================================
st.markdown("---")
st.markdown("""
### üéØ **Instru√ß√µes de Uso:**

**üî¥ Webcam:**
- Clique em **START** para iniciar a c√¢mera
- Aguarde alguns segundos para a inicializa√ß√£o
- Verifique as permiss√µes do navegador se a c√¢mera n√£o aparecer

**üñºÔ∏è Imagem:**
- Carregue uma imagem PNG/JPG
- A detec√ß√£o ser√° processada automaticamente

**üé• V√≠deo:**
- Carregue um v√≠deo MP4/AVI/MOV
- Use o bot√£o **Parar Processamento** para interromper

**‚öôÔ∏è Configura√ß√µes:**
- **YOLO**: Use modelos pr√©-treinados para detec√ß√£o precisa
- **Hough**: Ideal para objetos circulares simples
- Ajuste os par√¢metros conforme necess√°rio
""")